{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98779557a508068a",
   "metadata": {},
   "source": [
    "# Classification using a Support Vector Classifier (SVC)\n",
    "\n",
    "| Key              | Value                                                                                                                                                                                                                                                                                                |\n",
    "|:-----------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4106, BCM 3104, and BFS 4102                                                                                                                                                                                                                                                                     |\n",
    "| **Course Names** | BBT 4106: Business Intelligence I (Week 10-12 of 13),<br/>BCM 3104: Business Intelligence and Data Analytics (Week 10-12 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13)                                                                                                  |\n",
    "| **Semester**     | January to April 2026                                                                                                                                                                                                                                                                                |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                                                                                                                         |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                                                                                                                               |\n",
    "| **Note**         | The lecture contains both theory and practice.<br/>This notebook forms part of the practice.<br/>It is intended for educational purpose only.<br/>Recommended citation: [BibTex](https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/RecommendedCitation.bib) |\n",
    "\n",
    "**Business context**: A business has a strategic objective to *increase the number of purchases made by customers by 20% by the end of the current financial year*. The lagging KPI in the financial perspective of the business' performance is the number of purchases whereas its leading KPI is the number of visits to the eCommerce website. The business would like to predict whether a customer will make a purchase so that the marketing and sales teams can intervene early and increase the number of purchases.\n",
    "\n",
    "**Dataset**: The dataset used in this notebook is based on the **\"Online Shoppers Purchasing Intention\"** dataset. It contains 12,330 observations where each observation represents a user session on an eCommerce website. The dataset includes various features such as the number of pages viewed, time spent on the website, whether the user made a purchase (the target variable), etc. as described [here](https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset) and listed below.\n",
    "\n",
    "| **Feature Type** | **Feature Name**          | **Description**                                                                                      |\n",
    "|:-----------------|:--------------------------|:-----------------------------------------------------------------------------------------------------|\n",
    "| **Feature**      | `Administrative`          | Number of administrative pages viewed by the user                                                    |\n",
    "| **Feature**      | `Administrative_Duration` | Total time spent on administrative pages in seconds                                                  |\n",
    "| **Feature**      | `Informational`           | Number of informational pages viewed by the user                                                     |\n",
    "| **Feature**      | `Informational_Duration`  | Total time spent on informational pages in seconds                                                   |\n",
    "| **Feature**      | `ProductRelated`          | Number of product-related pages viewed by the user                                                   |\n",
    "| **Feature**      | `ProductRelated_Duration` | Total time spent on product-related pages in seconds                                                 |\n",
    "| **Feature**      | `BounceRates`             | Bounce rate of the session (percentage of single-page visits)                                        |\n",
    "| **Feature**      | `ExitRates`               | Exit rate of the session (percentage of exits from the site)                                         |\n",
    "| **Feature**      | `PageValues`              | Average value of the pages viewed in the session (monetary value)                                    |\n",
    "| **Feature**      | `SpecialDay`              | Number of special days (e.g., holidays) in the session                                               |\n",
    "| **Feature**      | `Month`                   | Month of the session (encoded as a numeric value)                                                    |\n",
    "| **Feature**      | `OperatingSystems`        | Operating system used by the user (encoded as a numeric value)                                       |\n",
    "| **Feature**      | `Browser`                 | Browser used by the user (encoded as a numeric value)                                                |\n",
    "| **Feature**      | `Region`                  | Region of the user (encoded as a numeric value)                                                      |\n",
    "| **Feature**      | `TrafficType`             | Type of traffic that brought the user to the site (encoded as a numeric value)                       |\n",
    "| **Feature**      | `VisitorType`             | Type of visitor (e.g., Returning Visitor, New Visitor) encoded as a numeric value                    |\n",
    "| **Feature**      | `Weekend`                 | Indicates if the session occurred on a weekend (encoded as a numeric value, 0 for False, 1 for True) |\n",
    "| **Target**       | `Revenue`                 | Indicates if the user made a purchase (1 for Yes, 0 for No)                                          |\n",
    "\n",
    "**Remote Environments:**\n",
    "\n",
    "Do your best to setup your local environment as guided during the lab, however, if you have challenges setting it up, then you can use the following remote environments temporarily for the lab:<br/>\n",
    "\n",
    "[![Colab](https://img.shields.io/badge/Open-Colab-orange?logo=googlecolab)](\n",
    "https://colab.research.google.com/github/course-files/RegressionAndClassification/blob/main/4_svm.ipynb) (preferred option)\n",
    "\n",
    "[![Codespaces](https://img.shields.io/badge/Open-Codespaces-blue?logo=github)](\n",
    "https://github.com/codespaces/new/course-files/RegressionAndClassification) (alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f4645b58c95cc",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736c6efde978277",
   "metadata": {},
   "source": [
    "**Purpose**: This chunk imports all the necessary libraries for data analysis, machine learning, and visualization.\n",
    "\n",
    "1. **For File and system operations [urllib3](https://urllib3.readthedocs.io/en/stable/)**\n",
    "    - `urllib.request` is used for opening and downloading data from URLs.\n",
    "    - `os` provides functions for interacting with the operating system, such as file and directory management.\n",
    "    - The `import sys` statement allows access to Python's system-specific parameters and functions, such as command-line arguments and the interpreter environment.\n",
    "    - `sys` is imported to check if the code is running in Google Colab or not, which can affect how files are downloaded or saved.\n",
    "\n",
    "2. **For data manipulation - [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html) and [numpy](https://numpy.org/doc/stable/):**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "    - `numpy as np`: For numerical operations and array manipulations\n",
    "\n",
    "3. **For statistical data analysis - [scipy.stats](https://docs.scipy.org/doc/scipy/tutorial/stats.html)**\n",
    "    - `kurtosis`: Measures the \"tailedness\" of data distribution\n",
    "    - `skew`: Measures the asymmetry of data distribution\n",
    "\n",
    "4. **For data preprocessing and transformation - [scikit-learn.preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)**\n",
    "    - `LabelEncoder`: LabelEncoder from scikit-learn converts categorical text labels (e.g., cat, dog, mouse) into numerical values (e.g., 0, 1, 2). It is used to prepare categorical data for machine learning algorithms that require numeric inputs\n",
    "    - `StandardScaler`: For feature scaling\n",
    "\n",
    "5. **For Machine Learning - [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html)**\n",
    "    - `DecisionTreeClassifier`: A class from scikit-learn that implements the CART (Classification and Regression Trees) algorithm for building decision tree models.\n",
    "    - `plot_tree`: A function from scikit-learn’s tree module that visualizes the decision tree structure.\n",
    "    - `train_test_split`: A function from scikit-learn’s model_selection module that splits the dataset into training and testing sets.\n",
    "    - `classification_report`: A function from scikit-learn’s metrics module used to evaluate the performance of the classifier. It gives detailed metrics such as precision, recall, f1-score, and support for each class.\n",
    "    - `confusion_matrix`: A function from scikit-learn’s metrics module that computes the confusion matrix to evaluate the accuracy of a classification.\n",
    "    - `GridSearchCV`: For hyperparameter tuning using cross-validation\n",
    "\n",
    "6. **For data visualization - [matplotlib](https://matplotlib.org/stable/gallery/index.html) and [seaborn](https://seaborn.pydata.org/examples/index.html)**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `seaborn as sns`: For enhanced statistical visualizations\n",
    "\n",
    "7. **For model persistence - [joblib](https://joblib.readthedocs.io/en/stable/)**\n",
    "    - `joblib` is used for saving and loading Python objects, such as machine learning models, to and from disk.\n",
    "\n",
    "8. **For suppressing warnings - [warnings](https://docs.python.org/3/library/warnings.html)**\n",
    "    - `warnings`: Controls warning messages\n",
    "    - `warnings.filterwarnings('ignore')`: Suppresses warning messages for cleaner output\n",
    "    - Used to suppress warnings that may arise during the execution of the code. Even though it is not necessary for the code to run, it helps in keeping the output clean and focused on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5688d4",
   "metadata": {},
   "source": [
    "Confirm the following:\n",
    "1. Which Python interpreter will be used to execute new code and where it is located\n",
    "2. The Python version\n",
    "\n",
    "Then install all the packages into the Jupyter notebook's virtual environment before importing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b40723b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\aomondi\\\\Documents\\\\GitHub\\\\Teaching\\\\RegressionAndClassification\\\\.venv\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e60ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.14.2\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee13b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing in dev environment\n",
      "Requirement already satisfied: numpy in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (3.10.8)\n",
      "Requirement already satisfied: seaborn in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: pytest in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 4)) (9.0.2)\n",
      "Requirement already satisfied: pytest-cov in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 5)) (7.0.0)\n",
      "Requirement already satisfied: black in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 6)) (25.12.0)\n",
      "Requirement already satisfied: flake8 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 7)) (7.3.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (9.9.0)\n",
      "Requirement already satisfied: jupyter in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pandas->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pandas->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pandas->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 3)) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from scikit-learn->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 4)) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from scikit-learn->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from matplotlib->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 5)) (3.3.1)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pytest->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pytest->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pytest->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from pytest->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 4)) (2.19.2)\n",
      "Requirement already satisfied: coverage>=7.10.6 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from coverage[toml]>=7.10.6->pytest-cov->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 5)) (7.13.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from black->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 6)) (8.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from black->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from black->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 6)) (1.0.2)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from black->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 6)) (4.5.1)\n",
      "Requirement already satisfied: pytokens>=0.3.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from black->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from flake8->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from flake8->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 7)) (2.14.0)\n",
      "Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from flake8->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (3.0.52)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (0.2.14)\n",
      "Requirement already satisfied: notebook in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (7.5.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (7.1.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jedi>=0.18.1->ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (0.8.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/base.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.8.19)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (8.7.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (5.9.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (7.2.1)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (6.5.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipywidgets->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from ipywidgets->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.0.16)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (80.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.13.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.26.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.32.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.30.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.14.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.21.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.6.3)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: cffi>=2.0.0b1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from cffi>=2.0.0b1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.23)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (4.15.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\aomondi\\documents\\github\\teaching\\regressionandclassification\\.venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt (line 9)) (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Installing in Google Colab\")\n",
    "    %pip install -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/colab.txt\n",
    "else:\n",
    "    print(\"Installing in dev environment\")\n",
    "    %pip install -r https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/dev.txt -c https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/requirements/constraints.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T05:55:22.064403Z",
     "start_time": "2025-07-07T05:55:21.998317Z"
    }
   },
   "outputs": [],
   "source": [
    "# For file and system operations\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data preprocessing and transformation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# For model persistence\n",
    "import joblib\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa681e97ffbe68a9",
   "metadata": {},
   "source": [
    "## Step 2: Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc3b3d592994f4",
   "metadata": {},
   "source": [
    "**Purpose**: This chunk loads the dataset by checking if the dataset exists locally; if not, then it downloads it from the specified URL and saves it locally before loading it into a Pandas DataFrame.\n",
    "\n",
    "- **Data Loading Parameters**\n",
    "    - Uses `pd.read_csv()` with specific parameters:\n",
    "        - `usecols`: Loads only the columns specified in `use_cols` for memory efficiency\n",
    "        - `encoding='utf-8'`: Handles special characters in the dataset. This is suitable for most languages and special characters like ñ, €, ®. Other alternative encodings include:\n",
    "        - `encoding='utf-16'`: Supports multilingual characters, uses 2 Bytes per character.\n",
    "        - `encoding='utf-32'`: Like utf-16 but uses 4 Bytes per character, suitable for full Unicode range.\n",
    "        - `encoding='latin-1'`: Handles Western European characters such as ñ, ß, € without throwing decode errors.\n",
    "        - `encoding='big5'`: Traditional Chinese encoding used in Taiwan and Hong Kong.\n",
    "        - `encoding='shift_jis'`: Japanese character encoding used on Windows.\n",
    "        - You can try different encodings if you encounter the `UnicodeDecodeError` while reading a file. This is useful in cases where the business has branches across different countries and the dataset contains characters from multiple languages.\n",
    "        - `nrows=200000`: Limits the number of rows loaded to 200,000. This can be reduced or increased based on the available memory and the size of the dataset.\n",
    "    - The data is then stored in a `Pandas` DataFrame for further analysis\n",
    "    - This selective loading approach helps manage memory usage and focuses the analysis on the relevant features for the design of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35aa1676d3b43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data/online_shoppers_intention.csv'\n",
    "url = 'https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/data/online_shoppers_intention.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    if not os.path.exists('./data'):\n",
    "        os.makedirs('./data')\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"✅ Dataset downloaded\")\n",
    "else:\n",
    "    print(\"✅ Dataset already exists locally\")\n",
    "\n",
    "use_cols = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "            'Informational_Duration', 'ProductRelated',\n",
    "            'ProductRelated_Duration', 'BounceRates', 'ExitRates',\n",
    "            'PageValues', 'SpecialDay', 'Month', 'OperatingSystems',\n",
    "            'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend',\n",
    "            'Revenue']\n",
    "online_shoppers_intention_data = pd.read_csv(dataset_path, usecols=use_cols, encoding='utf-8', nrows=200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7d1125e014aa7",
   "metadata": {},
   "source": [
    "### Identify the numeric and categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086fac18dad1ee5",
   "metadata": {},
   "source": [
    "**Selection of numeric columns**\n",
    "- The code identifies columns with numeric data types (`int64` and `float64`) that can be subjected to mathematical or statistical functions.\n",
    "- The code also identifies non-numeric columns (e.g., `strings`, `objects`, etc.) by excluding numeric (`int64`, `float64`) and `datetime` data types.\n",
    "- This is done using `select_dtypes()` method of the DataFrame, which filters columns based on their data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c562652b32256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = online_shoppers_intention_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = online_shoppers_intention_data.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']).columns\n",
    "\n",
    "print(\"\\nThe identified numeric columns are:\")\n",
    "print(numeric_cols.tolist())\n",
    "\n",
    "print(\"\\nThe identified categorical columns are:\")\n",
    "print(categorical_cols.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1804c1012a75f",
   "metadata": {},
   "source": [
    "## Step 3: Initial Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb420ea4e97a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n*1* The number of observations and variables\")\n",
    "display(online_shoppers_intention_data.shape)\n",
    "\n",
    "print(\"\\n*2* The data types:\")\n",
    "display(online_shoppers_intention_data.info())\n",
    "\n",
    "print(\"\\n*3* The summary of the numeric columns:\")\n",
    "display(online_shoppers_intention_data.describe())\n",
    "\n",
    "print(\"\\n*4* The whole dataset:\")\n",
    "display(online_shoppers_intention_data)\n",
    "\n",
    "print(\"\\n*5* The first 5 rows in the dataset:\")\n",
    "display(online_shoppers_intention_data.head())\n",
    "\n",
    "print(\"\\n*6* Percentage distribution for each category\")\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", online_shoppers_intention_data['Revenue'].value_counts())\n",
    "print(\"\\nPercentages:\\n\", online_shoppers_intention_data['Revenue'].value_counts(normalize=True) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c738014ebdfc37",
   "metadata": {},
   "source": [
    "## Step 4: Data preprocessing and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a826f6e5fe4d3ec",
   "metadata": {},
   "source": [
    "### Resample with replacement to balance the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d2b9ed11f4138",
   "metadata": {},
   "source": [
    "- **Purpose**: The purpose of this step is to balance the dataset by upsampling the minority class (where `Revenue` is 1) to match the number of observations in the majority class (where `Revenue` is 0`). This helps to mitigate the class imbalance problem, which can lead to biased model predictions.\n",
    "- **Resampling**: The `resample` function from `sklearn.utils` is used to create a balanced dataset by:\n",
    "    - Separating the majority and minority classes based on the `Revenue` column.\n",
    "    - Upsampling the minority class by sampling with replacement to match the number of observations in the majority class.\n",
    "    - Combining the upsampled minority class with the majority class to create a balanced dataset.\n",
    "        - `replace=True`: This allows sampling with replacement, meaning the same observation can be selected multiple times.\n",
    "        - `n_samples=len(df_majority)`: This ensures that the number of samples in the upsampled minority class matches the number of samples in the majority class.\n",
    "        - `random_state=53`: This sets a random seed for reproducibility, ensuring that the same random samples are selected each time the code is run.\n",
    "        - **Combining**: The upsampled minority class is combined with the majority class using `pd.concat()`, resulting in a balanced dataset.\n",
    "        - **Final Dataset**: The final balanced dataset is stored in `df_balanced`, and the features and target variable are separated into `X_balanced` and `y_balanced` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda3244eb59bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = online_shoppers_intention_data[online_shoppers_intention_data['Revenue']==0]\n",
    "df_minority = online_shoppers_intention_data[online_shoppers_intention_data['Revenue']==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                               replace=True,     # Sample with replacement\n",
    "                               n_samples=len(df_majority),    # To match the majority class\n",
    "                               random_state=53)  # To ensure the results are reproducible\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "online_shoppers_intention_data = df_balanced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ee265fac592",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", online_shoppers_intention_data['Revenue'].value_counts())\n",
    "print(\"\\nPercentages:\\n\", online_shoppers_intention_data['Revenue'].value_counts(normalize=True) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140bbfee73f325c",
   "metadata": {},
   "source": [
    "### Represent the non-numeric, categorical columns as numeric using label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd11c78ca98c70",
   "metadata": {},
   "source": [
    "- We need to convert the data into a numeric format suitable for the model\n",
    "- First, we map the boolean `Revenue` target to integers (0 and 1)\n",
    "- Then we encode any categorical variables into numeric form. In this dataset, columns like `VisitorType`, `Weekend`, and `Month` are categorical. We can use label encoding for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbfd6080299c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the target 'Revenue' from False/True to 0/1\n",
    "online_shoppers_intention_data['Revenue'] = online_shoppers_intention_data['Revenue'].map({False: 0, True: 1})\n",
    "\n",
    "# Create a dictionary to store the label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode the categorical columns: 'VisitorType', 'Weekend', and 'Month'\n",
    "for col in ['VisitorType', 'Weekend', 'Month']:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    online_shoppers_intention_data[col] = label_encoders[col].fit_transform(online_shoppers_intention_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f426fc76be70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_shoppers_intention_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780f28b3f8052bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_shoppers_intention_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b70aa4c7177b7e",
   "metadata": {},
   "source": [
    "### Create X and y datasets for the features and target variable respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba4d9f4354d26c",
   "metadata": {},
   "source": [
    "- `X = ...`: Separates the data such that the *DataFrame* called `X` contains only the features (independent variables or predictors)\n",
    "    - `axis=0` drops the concerned rows.\n",
    "    - `axis=1` drops the concerned columns.\n",
    "\n",
    "- `y = ...`: Separates the data such that the *Series* called `y` contains only the target (dependent variable or outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb1d7e14e81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = online_shoppers_intention_data.drop('Revenue', axis=1)\n",
    "y = online_shoppers_intention_data['Revenue']\n",
    "\n",
    "print(\"\\nThe number of observations and variables in the features dataset\")\n",
    "print(X.shape)\n",
    "print(\"\\nThe columns in the features dataset\")\n",
    "print(X.columns)\n",
    "\n",
    "print(\"\\nThe number of observations and variables in the target dataset\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714e5f08d77798b",
   "metadata": {},
   "source": [
    "### Train‑test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5c5f0235b273d",
   "metadata": {},
   "source": [
    "- This step splits the dataset into training and testing sets to evaluate the model's performance on unseen data. The `train_test_split()` function is used to randomly split the data, ensuring that the target variable's distribution is preserved in both sets.\n",
    "- `stratify=y` in train_test_split ensures that the train and test sets have the same proportion of each class label as the original dataset. This is important for classification tasks, especially when classes are imbalanced, as it preserves the class distribution in both splits.\n",
    "- `test_size=0.3` indicates that 30% of the data will be used for testing, while 70% will be used for training.\n",
    "- `random_state=53` ensures reproducibility of the split, meaning that every time you run the code, you will get the same split of data.\n",
    "- `StandardScaler()` is used to standardize the features by setting mean = 0 and variance = 1. This is important for kNN, as it is sensitive to the scale of the features. Standardization ensures that all features contribute equally to the distance calculations.\n",
    "- `fit_transform()` is applied to the training data to compute the mean and standard deviation, and then transform the data accordingly.\n",
    "- `transform()` is applied to the test data using the same scaler fitted on the training data. This ensures that the test data is scaled in the same way as the training data, preventing data leakage.\n",
    "\n",
    "- The `train_test_split` function returns four objects:\n",
    "  - `X_train`: features for training\n",
    "  - `X_test`: features for testing\n",
    "  - `y_train`: labels for training\n",
    "  - `y_test`: labels for testing\n",
    "\n",
    "**Why:** Splitting the data this way allows you to train your model on one part of the data and evaluate its performance on unseen data, which helps prevent overfitting and gives an objective measure of the model's accuracy.\n",
    "\n",
    "*Analogy:* This is similar to how a student learning a subject is not exposed to only one past paper that they can memorize. If they memorize the past paper and the exam assesses them on a different set of questions, then their performance in the exam will not be the same as their performance in the memorized past paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa619fd9ed0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into a training set and a test set (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0156aba8a33d7",
   "metadata": {},
   "source": [
    "### Apply scaling to the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072bdd12e459b4f",
   "metadata": {},
   "source": [
    "`StandardScaler` is a preprocessing technique from scikit-learn whose purpose is to standardize features by removing the mean and scaling it to a unit variance. It does this by applying the standardization formula to each feature:\n",
    "- Standardization formula: `z = (x - μ) / σ`\n",
    "- Where:\n",
    "   - `x` is the original value of the feature.\n",
    "   - `μ` is the mean of the feature values.\n",
    "   - `σ` is the standard deviation of the feature values.\n",
    "- The result is:\n",
    "    - The transformed data will have a mean of 0\n",
    "    - Standard deviation of 1\n",
    "    - Roughly 68% of the values will lie between -1 and 1\n",
    "    - Roughly 95% of the values will lie between -2 and 2\n",
    "\n",
    "- Advantages:\n",
    "    - Makes features comparable when their original versions are on different scales\n",
    "    - Many machine learning algorithms perform better when features are on similar scales\n",
    "    - Particularly important for algorithms that use distance calculations or assume normally distributed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ffd1c55745cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51ad13279a1c85",
   "metadata": {},
   "source": [
    "## Step 5: Design a baseline Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12c0c974be62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "support_vector_classifier_baseline = SVC(random_state=53)\n",
    "\n",
    "# Fit the model on the training data\n",
    "support_vector_classifier_baseline.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8237c564e036d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = support_vector_classifier_baseline.predict(X_test_scaled)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Overall fraction of correct predictions\n",
    "\n",
    "# Show precision, recall, F1-score for each class\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute and display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b51e6b156f18ee",
   "metadata": {},
   "source": [
    "## Step 6: Perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391f6e341193705",
   "metadata": {},
   "source": [
    "**Hyperparameters:**\n",
    "\n",
    "- `C`: Regularization parameter. Controls the trade-off between achieving a low training error and a low testing error (generalization). Smaller values specify stronger regularization.\n",
    "- `kernel`: Specifies the kernel type to be used in the algorithm. Common options are 'linear' (linear decision boundary) and 'rbf' (nonlinear, radial basis function).\n",
    "- `gamma`: Kernel coefficient for 'rbf', 'poly', and 'sigmoid'. It defines how far the influence of a single training example reaches. 'scale' and 'auto' are automatic settings based on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5663bc32f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV for SVC\n",
    "grid_search = GridSearchCV(\n",
    "    support_vector_classifier_baseline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the scaled training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best estimator as your tuned model\n",
    "support_vector_classifier_optimum = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8feab7b12283e0",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a653c7d",
   "metadata": {},
   "source": [
    "`y_pred = model.predict(X_test)`\n",
    "\n",
    "- This uses the trained decision tree classifier (`model`) to predict the labels for the test set features (`X_test`). This gives you the model’s predictions on data it has not seen before, which is necessary for evaluating its performance.\n",
    "\n",
    "`print(\"Classification Report:\\n\", classification_report(y_test, y_pred))`\n",
    "- This prints a detailed classification report comparing the true labels (`y_test`) to the predicted labels (`y_pred`). The report includes precision, recall, F1-score, and support for each class, enabling you to understand how well the model performs for each category.\n",
    "- It shows the performance metrics for a model that predicts two classes:\n",
    "    - Class 0 - A case where the user's interaction with the eCommerce website does not lead to a purchase.\n",
    "    - Class 1 - A case where the user's interaction with the eCommerce website leads to a purchase.\n",
    "\n",
    "| Term             | Meaning                                                                                                                             |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Precision**    | Out of all items the model said are class X, how many are actually class X?                                                         |\n",
    "| **Recall**       | Out of all actual items in class X, how many did the model correctly find?                                                          |\n",
    "| **F1-score**     | A balance between precision and recall such  that a higher value means better balance.                                              |\n",
    "| **Support**      | The number of actual items in that class.                                                                                           |\n",
    "| **Macro avg**    | The average of precision, recall, and F1-score for both classes, treating them equally.                                             |\n",
    "| **Weighted avg** | The average of precision, recall, and F1-score, but weighted by how many samples are in each class (so class 1 has more influence). |\n",
    "\n",
    "- The results show that the model is much better at predicting class 1 than class 0, and overall gets 75% of predictions correct. This may be because there are more class 1 cases in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f4acf0fa0c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = support_vector_classifier_optimum.predict(X_test_scaled)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Overall fraction of correct predictions\n",
    "\n",
    "# Show precision, recall, F1-score for each class\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute and display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e725ee7fb758e",
   "metadata": {},
   "source": [
    "## Step 8: Use the model to make a prediction on a new sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2539687008f0e4",
   "metadata": {},
   "source": [
    "### Predictions using new data provided in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4012562358e7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new data as a DataFrame\n",
    "new_data_original = pd.DataFrame({\n",
    "    'Administrative': [2, 5],\n",
    "    'Administrative_Duration': [50.0, 60.0],\n",
    "    'Informational': [0, 4],\n",
    "    'Informational_Duration': [0.0, 116],\n",
    "    'ProductRelated': [20, 50],\n",
    "    'ProductRelated_Duration': [400.0, 600.0],\n",
    "    'BounceRates': [0.02, 0],\n",
    "    'ExitRates': [0.05, 0.006593407],\n",
    "    'PageValues': [0.0, 6.281494505],\n",
    "    'SpecialDay': [0.0, 0.0],\n",
    "    'Month': ['Nov', 'Jul'],\n",
    "    'OperatingSystems': [2, 1],\n",
    "    'Browser': [1, 3],\n",
    "    'Region': [1, 9],\n",
    "    'TrafficType': [2, 1],\n",
    "    'VisitorType': ['Returning_Visitor', 'New_Visitor'],\n",
    "    'Weekend': ['False', 'True']\n",
    "})\n",
    "\n",
    "new_data = new_data_original.copy()\n",
    "\n",
    "# Encode categorical columns using the same label encoders\n",
    "for col in ['VisitorType', 'Weekend', 'Month']:\n",
    "    new_data[col] = label_encoders[col].transform(new_data[col])\n",
    "\n",
    "# Scale the features using the same scaler as training\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Predict\n",
    "prediction = support_vector_classifier_optimum.predict(new_data_scaled)\n",
    "print(prediction)\n",
    "\n",
    "# Add predictions as a new column\n",
    "new_data_original['Predicted_Revenue'] = prediction\n",
    "display(new_data_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f094381f01cf112",
   "metadata": {},
   "source": [
    "### Predictions using new data provided in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d13cb0fa47110",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data/online_shoppers_intention_new_data.csv'\n",
    "url = 'https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/data/online_shoppers_intention_new_data.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    if not os.path.exists('./data'):\n",
    "        os.makedirs('./data')\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"✅ Dataset downloaded\")\n",
    "else:\n",
    "    print(\"✅ Dataset already exists locally\")\n",
    "\n",
    "use_cols = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "            'Informational_Duration', 'ProductRelated',\n",
    "            'ProductRelated_Duration', 'BounceRates', 'ExitRates',\n",
    "            'PageValues', 'SpecialDay', 'Month', 'OperatingSystems',\n",
    "            'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend',\n",
    "            'Revenue']\n",
    "new_data_original = pd.read_csv(dataset_path, usecols=use_cols, encoding='utf-8', nrows=200000)\n",
    "new_data = new_data_original.drop(['Revenue'], axis=1).copy()\n",
    "\n",
    "# Encode categorical columns using the same label encoders\n",
    "for col in ['VisitorType', 'Weekend', 'Month']:\n",
    "    new_data[col] = label_encoders[col].transform(new_data[col])\n",
    "\n",
    "# Scale the features using the same scaler as training\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Predict\n",
    "predictions = support_vector_classifier_optimum.predict(new_data_scaled)\n",
    "new_data_original['Predicted_Revenue'] = predictions\n",
    "display(new_data_original.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101386ebe33f3ae",
   "metadata": {},
   "source": [
    "## Step 9: Export the results for further analysis and reporting using a tool like Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404b83aa109386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results as a CSV file for further analysis and reporting\n",
    "output_path = './data/online_shoppers_intention_predicted_data_svc.csv'\n",
    "# Ensure the data directory exists\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "# Save the CSV file regardless of environment (Google Colab or local)\n",
    "new_data_original.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Results saved to {output_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped dataset download link.\")\n",
    "\n",
    "# Save the label encoders\n",
    "label_encoders_path = './model/label_encoders_4.pkl'\n",
    "# Ensure the model directory exists\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "joblib.dump(label_encoders, label_encoders_path)\n",
    "print(f\"✅ Label encoders saved to {label_encoders_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(label_encoders_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped label encoder download link.\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = './model/scaler_4.pkl'\n",
    "# Ensure the model directory exists\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"✅ Scaler saved to {scaler_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(scaler_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped scaler download link.\")\n",
    "\n",
    "# Save the model\n",
    "model_path = './model/support_vector_classifier_optimum.pkl'\n",
    "# Ensure the model directory exists\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "# Save the model regardless of environment (Google Colab or local)\n",
    "joblib.dump(support_vector_classifier_optimum, model_path)\n",
    "print(f\"✅ Model saved to {model_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(model_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped model download link.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd07315fe071cdf",
   "metadata": {},
   "source": [
    "# Refences\n",
    "Sakar, C. & Kastro, Y. (2018). Online Shoppers Purchasing Intention Dataset [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5F88Q."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
